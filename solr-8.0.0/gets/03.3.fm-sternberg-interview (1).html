<HTML><HEAD><TITLE>Skeptic Interview with Robert Sternberg</TITLE>
<LINK REV = "made" HREF = "mailto:lippard@skeptic.com">
</HEAD>
<BODY>
From <EM>Skeptic</EM> vol. 3, no. 3, 1995, pp. 72-80.
<P>The following article is copyright &#169 1995 by the Skeptics Society,
P.O. Box 338, Altadena, CA 91001, (818) 794-3119.  Permission
has been granted for noncommercial electronic circulation of this
article in its entirety, including this notice.
<A HREF = "skeptic-subs.html">  A special Internet introductory subscription
rate to <EM>Skeptic</EM> is available.</A>
For more information, contact Jim Lippard (lippard@skeptic.com).</P>

<H1><EM>Skeptic</EM> Magazine Interview With Robert Sternberg on <EM>The Bell Curve</EM></H1>
<H2><A HREF = "03.3.about-miele.html">Interview by Frank Miele</A></H2>

Even though it was written for the media, Herrnstein and Murray's book
has greatly increased public confusion and misconception about the
relationship between heritability and environment.

<P>Robert Sternberg's history with intelligence testing has been
described as a lifelong love-hate affair. In the 6th grade, suffering
from test anxiety, he performed so poorly on a standardized test the
school authorities made him take the test a second time with a group
of 5th graders. Feeling confident among that group, he did quite
well. (He describes the incident and its effect on him and his
subsequent research in more detail in the interview.)  By the 7th
grade he had developed his own intelligence test dubbed the STOMA-the
Sternberg Test of Mental Ability (he was certainly not lacking in
initiative). As an undergraduate, Sternberg majored in psychology at
Yale, and managed to get only a "C" in his introductory psych
course. Once again he proved that such early predictors are not all
they are cracked up to be. By the time he was a graduate student in
psychology at Stanford, his doctoral work earned him the Sidney Siegel
Memorial Award. He has worked at the Admissions Office and the
Institutional Research Office at Yale University, the Test Division of
the Psychological Corporation, and at the Educational Testing Service
(ETS).
<P>   Sternberg's early work built on the standard psychometric
conception of intelligence as a single, general trait (Spearman's
g). His Componential Theory broke g down into its underlying
information processing components.  But Sternberg found that even his
Componential Theory and the tests he developed to measure the
component processes still missed a lot. Individuals who scored highly
on Sternberg's early test still were not guaranteed success and many
individuals who did not score as well went on to have a better record
of real life accomplishments than did those who scored well on his or
on other traditional tests.
<P>   Sternberg has moved beyond the Componential Theory to what is now
known as the Triarchic Theory of Intelligence. In his view, the
Triarchic Theory does not disprove either g or his earlier
Componential Theory, but rather subsumes them under a larger
framework.
<P>   The Triarchic Theory posits three facets that make up what we call
intelligence (and for Sternberg that term, when properly defined and
measured, must translate into real life success). The three facets
are: (1) Analytical Intelligence, which is similar to the standard
psychometric definition of intelligence and corresponds to his earlier
Componential Intelligence. It is measured by analogies and puzzles and
reflects how an individual relates to his internal world; (2) Creative
Intelligence which involves insight, synthesis, and the ability to
react to novel stimuli and situations. This is the Experiential aspect
of intelligence and reflects how an individual connects the internal
world to external reality; (3) Practical Intelligence, which involves
the ability to grasp, understand, and solve real life problems in the
everyday jungle of life. This is the contextual aspect of
intelligence, and reflects how the individual relates to the external
world about him. In short, practical intelligence is "street smarts."
<P>   The Sternberg Multidimensional Abilities Test measures all three
(on separate scales). All three are important to success in life and
have been used to develop programs for children and to select business
managers. Together, the three measures provided more information than
just the analytical intelligence measured by standard IQ tests on
which, in Sternberg's view, our society has placed far too much
emphasis.
<P>   <EM>Skeptic</EM> went to Professor Sternberg to get his view of the
controversial book <EM>The Bell Curve</EM> (see the interview with its
co-author Charles Murray in the previous issue of <EM>Skeptic</EM>). Having
first discovered, then grasped, and for years fondled its trunk,
Sternberg feels that the standard psychometric interpretation (on
which so much of <EM>The Bell Curve</EM> (is based) has mistaken the elephant
of intelligence for nothing more than a big and powerful snake.
<P>   Sternberg also strongly believes that all three aspects of
intelligence can not only be measured, but also developed. While he
sees this technology as still being in the infant stage, Sternberg
believes it (and not just measurement and selection) is the goal on
which society should focus.
<P>   In 1981, Sternberg received the Distinguished Scientist Award for
Early Contribution of Psychology. The citation read, in part, "He has
put intelligence into investigations of intellectual
abilities...combining experimental methods and theories of cognitive
psychology with traditional mental-testing ideas in analyzing
intelligent performance and individual differences...[and has]
cross-fertilized and infused vitality into studies of individual
differences and the experimental analysis of intellectual
performances." He is currently IBM Professor of Education and
Psychology at Yale and the author of <EM>The Triarchic Mind</EM>, and
<EM>Intelligence, Information Processing and Analogical Reasoning</EM>. He is
also the editor of <EM>The Encyclopedia of Intelligence</EM>, and on the
editorial board of Intelligence, the leading scientific journal in the
field of intelligence and mental ability.
<P>   Like Charles Murray, Robert Sternberg thinks that the study of
intelligence is vitally important to the health and survival of our
society, but oh how their diagnoses and prescriptions differ-to the
point of possible allegations of quackery and malpractice! Here then
is what "the Street Smart Psychologist" had to say about <EM>The Bell
Curve</EM>.

<P><EM>Skeptic</EM>: At <EM>Skeptic</EM> magazine, we are interested in examining the
evidence for all claims. Herrnstein and Murray present what they
consider to be the consensus of scholars working in the field of
intelligence. Snyderman and Rothman (<EM>The IQ Controversy</EM>) present
similar data and there was a statement recently in the <EM>The Wall Street
Journal</EM>. You summarized this so-called consensus, if I can paraphrase,
in the following manner, "IQ exists, it's heritable, there are group
differences, and all this matters." But in your review of <EM>The Bell
Curve</EM> you say, "the lay public remains sadly uninformed.  Nothing
could be further from the truth." So as <EM>Skeptic</EM>s our question is, if
there is this much disagreement, is psychology even a science in the
same sense that physics is?

<P>Sternberg: There is disagreement in physics and there is disagreement
in biology. Active sciences always have disagreements within them. The
general public usually doesn't get the full sense of the amount of
disagreement because the information is filtered through the media and
what comes out is only a portion of what's actually going on in
science. Normally they would not even be aware of the disagreement in
psychology except that this book (<EM>The Bell Curve</EM>) was written for the
media. It was written with the purpose of stirring up this kind of
controversy. So the general public becomes aware of these types of
disagreements in psychology, but they exist in every active science.

<P><EM>Skeptic</EM>: Which then is a fairer description of your own position-(1)
there is a consensus on the topics that Herrnstein and Murray discuss,
or (2) yes, there is a consensus among psychometricians, but I (Robert
Sternberg) and others disagree with it?

<P>Sternberg: To the extent that there is a consensus it is certainly not
Herrnstein's and Murray's. You mentioned the statement that appeared
in the <EM>The Wall Street Journal</EM>, which a number of psychometricians
signed. This statement was not totally coincident with the views of
Herrnstein and Murray.  It certainly wasn't coincident with mine. I
would say that I don't think that consensus in science makes much
difference. Science isn't done by majority rule. There is a
misperception on the part of the public that even if you took a vote
and 51% of the scientists said, "I think this is true," that would
have any impact on whether it's really true or not. Science is not
politics. There could be one person who believes something and that
person might be right. In fact, most of the really important work in
science has been the result of one person saying, "You guys are all
wet, you're full of it!" and then proceeding to show that he is indeed
right. So I think the conception of science as taking a vote, and
whichever side gets 51% is right, is simply wrong. Science is not
politics, we're not electing anyone.

<P><EM>Skeptic</EM>: OK. Let's go point by point through the earlier paraphrase of
what's in <EM>The Bell Curve</EM>. Let's take the concept of general mental
ability, which Herrnstein and Murray invoke, versus Gardner's "Seven
Intelligences" or your own "Triarchic Mind," which uses the concepts
of Analytical Intelligence, Creative Intelligence, and Practical
Intelligence. You once wrote in an article that, "We interpret the
preponderance of evidence as overwhelmingly supporting the existence
of some kind of general factor in human intelligence. Indeed, we are
unable to find any convincing evidence at all that militates against
this view." So how then is your approach different than the approach
of the g-theorists that Herrnstein and Murray invoke?

<P>Sternberg: That article was published in 1983, I believe, and was
based on work that I had done in the late 70s and early 80s. What I
found at that time was that if you use the kinds of tasks that are
used in intelligence tests, then you will get the g factor. That
statement reflected analyses we did that instead of using individual
difference analysis used process analysis. Even using process
analysis, we got a general factor. So if you were to ask me, "Do I
think that there is general factor in the kinds of tests that
psychometricians use?" I would say "Yes." That is a different question
from, "If you define intelligence, not just as IQ, but as involving
more than what the IQ tests in fact test, is there then a general
factor?" then I would say the answer is "No." So the way
psychometricians operationalize it, you get a g factor. But I think,
as do many other people, that is a narrow view of intelligence.

<P><EM>Skeptic</EM>: Would it be fair to say that your view is not that g does not
exist, but that it is one facet or one side of the picture?

<P>Sternberg: That's right, g is not quite as general as some
psychometricians make it out to be.

<P><EM>Skeptic</EM>: Let's turn to the heritability of IQ. Let's just look at
that, as you described it, narrow measure we call IQ score, within the
white population. Herrnstein and Murray repeat the same numbers that
we find in reviews of the literature by Erlenmeyer-Kimling and Jarvik,
Bouchard and others. Do you have any disagreement with or criticism of
their estimate of .40 to .80 as the heritability of IQ score within
the white population?

<P>Sternberg: I think that there is definitely some heritability of
intelligence in the White population. Almost every psychologist
believes there is some heritability of IQ and I agree. But the public
may not understand just what that means. If you accept the use of the
heritability statistic, about .5 is probably right.

<P><EM>Skeptic</EM>: Can you explain wherein the general public's conception or
the media's description of what is meant by heritability is wrong?

<P>Sternberg: The commonplace understanding of heritability often doesn't
realize that heritability is calculated within a range of
environments, at a given time, for a given population. So heritability
is not the same in every population. In fact there is wide variation
in populations over time and space. It is not a fixed statistic. The
value you obtain (for heritability) depends on the population, where
it is, and when it is. But the major misunderstanding relates to the
role of the environment and to the role of teachability. With respect
to teachability, even if heritability is fairly high, it does not mean
that we cannot modify intelligence.

<P><EM>Skeptic</EM>: What exactly do you mean by that?

<P>Sternberg: What I mean is that there is absolutely no relation between
how heritable something is and the existence of a difference in group
means. The most common example is height. Height has a heritability of
greater than .9, but heights have increased quite dramatically in some
countries like Japan and have also increased in our own country over
the course of several generations. So despite the much higher
heritability of height than anyone believes of intelligence, we see
that height can increase. To take a more extreme example: there is a
disease known as Phenylketonuria (PKU), which is 100% heritable and
yet through an environmental intervention, namely withholding
Phenylalanine from the diets of infants from birth, you can either
reduce or eliminate the mental retardation that normally results. In
other words, even when heritability is 1.00, environmental
interventions still matter. There are different ways to look at
intelligence. One is to do heritability statistics, which I've never
found to be that helpful. Another way is to look at studies on
intervention. For example, Dennis did a large study in Iran where he
found that kids that were placed in Iranian orphanages, almost without
exception, were mentally retarded, whereas the children who were
quickly adopted before the age of two scored at normal levels on
intelligence tests, roughly a 50-point difference in obtained IQ.

<P><EM>Skeptic</EM>: Are such results repeatable?

<P>Sternberg: Yes. Obviously the environment of the Iranian orphanage was
pretty bad and that's why you got that level of retardation. But if
you look at the kinds of environments some of our least fortunate get,
even in the United States, in the inner cities, they are not so hot
either. Diamond performed studies on brain mass in rats and found that
if you give them an enriched environment, it affects the brain, which
becomes heavier and more convoluted.

<P><EM>Skeptic</EM>: How is your more elaborate view of heritability and its
limitations different from what Herrnstein and Murray say in <EM>The Bell
Curve</EM>?  Sternberg: The way that book is written is to, I think, say X
on page 605 in sentence 8, with an appropriate caution, and then
invite the reader to a somewhat more extreme conclusion elsewhere. So
if you were to ask, "Is there anywhere in <EM>The Bell Curve</EM> that explains
what heritability truly is?" there probably is. If you were to ask,
"What inference do Herrnstein and Murray invite their readers to
draw?" they go beyond what they know. For example, with regard to race
differences, Herrnstein and Murray invite the reader to conclude that
race differences are due to genetics, even though they have no
evidence of that, and they know it.

<P><EM>Skeptic</EM>: They do review studies that deal with race differences.

<P>Sternberg: Yes, but there is evidence that they do not review at
all. There is nothing in the book that suggests that race differences
are genetic. They even say that. But what they do say is that is what
we would infer given the data, even though probably somewhere else,
they would have one sentence to the effect that there is one
study. And they don't cite a number of studies that suggest that race
differences are not genetic.

<P><EM>Skeptic</EM>: Which studies don't Herrnstein and Murray cite?

<P>Sternberg: Well, one study that they cite and distort the results of
is the Scarr-Weinberg study. What Scarr-Weinberg and several people
have done is look at blood groups (associated with Whiteness or
Blackness), or skin color, and looked at the correlation with IQ. The
typical correlation is about .15, suggesting that you are accounting
for about 1-2% of the variance. And even that less than 2% could be
due to the way darker versus lighter people are treated. So when you
look at the studies that have been done, they counter-indicate the
conclusion that Herrnstein and Murray draw.

<P><EM>Skeptic</EM>: Which then is your position on the question of race
differences in IQ? We all see the 1 standard deviation difference in
mean IQ if we give the tests to groups of Blacks and Whites. Is that
mean difference the result of genetics, environment, both, or should
we say at this point that we just don't know?

<P>Sternberg: What we know is that almost any difference is some
interaction between heredity and environment. But in terms of
apportioning the difference, we have no idea. And I think that
Herrnstein and Murray know that as well as do other
psychologists. Like everyone else we don't like ambiguous situations,
so some jump to conclusions even though I think at this point we don't
have a very good idea of why we get that difference. Although we
recognize that it has generally been decreasing over time.

<P><EM>Skeptic</EM>: You say that Herrnstein and Murray build their whole argument
on the (often wrong) interpretations of statistics. Can you be more
specific?

<P>Sternberg: One example is taking studies that show that within group
heritabilities have nothing to do with between group heritabilities
and then insinuating that they do. Another example is the issue of
causation and correlation. They know, and anyone who takes statistics
knows, you can't draw any real causal conclusions from correlational
data. Lots of things correlate with lots of things, IQ being one of
them. To draw causal inferences from correlational data, which is what
all their data are, is statistically incorrect. Another thing that
many may not realize is that virtually all their data are based on one
study, the National Longitudinal Study of Youth (NLSY), which was not
a study that was particularly representative of the United States
population.

<P><EM>Skeptic</EM>: In what sense?

<P>Sternberg: The mean was low. I think the mean IQ in that group was
around 94 and the standard deviation was not 15 or 16. It was not a
typical US population. Another thing they do, in comparing
correlations, is that they don't take into account the reliability and
precision of the measures being used. For example, almost every
measure we use is a proxy for something else.  If you ask yourself,
"How good is 'number of years of schooling' for measuring how much
education a person has?" it's not a very good measure. Two people
could each have 16 years of schooling, but if you compare somebody who
was a straight A student in a really good college with someone who was
a D student in a really poor college, the number of years of education
will be the same but their educational attainments will be vastly
different. So as a measure of how much schooling you have really had,
years of education is extremely imprecise and it's not going to look
very good in correlational analyses. In contrast, IQ is a pretty good
measure of that narrow construct, compared to the other types of
measurement that we have. That will make IQ look more powerful than
the other measures because the other measures are such crude proxies
for the constructs that they are trying to measure.

<P><EM>Skeptic</EM>: Do we have better measures of what a person has accomplished?

<P>Sternberg: You could certainly measure their achievements with a
variety of kinds of tests. Those kinds of tests are
available. Herrnstein and Murray did not use them, but they are
available. I'm not saying that they are perfect, but what I am saying
is that the kinds of variables Herrnstein and Murray use, in contrast
to IQ, are generally not very reliable and not very good as proxies of
the constructs they are trying to measure. In terms of interpretation
another thing that I found strange was that the data suggest that IQs
generally have been going up (the Flynn Effect). Herrnstein and Murray
cite Flynn's work and they agree with it, but they then find
themselves in the awkward position of explaining why IQs are going up
when (according to Herrnstein and Murray), IQs should have been going
down. They then use very weak arguments to try to dismiss the Flynn
Effect, after making a big deal about its existence. In other words,
having committed themselves to a position, if the data are consistent
with their position, they cite them, and if the data are inconsistent,
they try to come up with what I think are fairly hare-brained
interpretations of how that could happen.

<P><EM>Skeptic</EM>: You refer in your review to Binet's "Mental Orthopedics" and
also to the work of Lev Vygotsky. These seem to be part of a different
paradigm that sees intelligence as something that grows or forms in a
social setting, and that sort of interpretation makes sense to most of
us. You even mention that Herrnstein at one point developed one of the
better programs for helping to raise IQ. Can you explain that further?

<P>Sternberg: Some years back in the early 1980s the government of
Venezuela initiated a country-wide drive to improve the intellectual
abilities of the children. They invited a number of researchers from
Venezuela and abroad to come in. One program was initiated by Harvard,
and Herrnstein was the head of that program. It was successful. They
published the results in <EM>American Psychologist</EM>, which is a leading
psychological journal, showing that there had been significant and
impressive gains in IQ.

<P><EM>Skeptic</EM>: How do you square that with, for example, Herman Spitz (who
signed the <EM>The Wall Street Journal</EM> statement) or even Zigler, who is
one of the gurus of Head Start, who says, "It does great things for
keeping children in school and out of jail, but IQ isn't something
that we can really move around a lot, we just don't know how to do
it." Again, there appears to be a contradiction between what the
authorities say.

<P>Sternberg: I don't think there would be that big a difference between
me and Zigler. You can get some increases. I don't think we know how
to get really large, long term increases. On the other hand, we're
talking about work that's been around for maybe 30 years. If you ask,
"how far had medicine gone in 30 years after its inception, say in
Ancient Greece in terms of curing illness," it wasn't that hot
either. We have just started on this kind of work. You can't expect
that in a fairly short amount of time we will have figured exactly
what to do. This field just isn't at that point yet.

<P><EM>Skeptic</EM>: Would you agree that the burden of proof should be on those
who claim, at this point, that they can raise IQ?

<P>Sternberg: Yes. And I think that it has been there. There have been
programs, Ramey's Carolina Abecedarian Project is another, that have
worked. I think it's hard to maintain the IQ gains. But if you think
environment is important in the development of intelligence, and you
put people in a really good program and you raise their IQ, and then
take them out of the program and put them back in the poor environment
in which they started, chances are you are going to lose a lot of the
beneficial effect. If you give someone antibiotics for a disease, cure
them, then put them back in the original septic environment, the
disease will return. We've seen this when we work with children with
parasitic infections. We can give them Albendazol and it will cure
their parasitic infection. But if you put them back in the environment
in which they acquired the infection, they will just acquire it again.

<P><EM>Skeptic</EM>: In another quote from your article, you say, "How strange
that we have become a society that values what someone might do more
than what he has done." Isn't that what all science is about-trying to
predict in advance?  Isn't the final practical test whether it works
economically in the real world? Isn't that what physics, astronomy,
and chemistry, all strive for?

<P>Sternberg: No. And if you were to tell someone in physics that the
final test is whether it works economically in the real world, they
would tell you that that has nothing to do with truth at all. It's
totally irrelevant to what is scientifically true. There is a question
of what is true and then there is a question of how you use it. But I
don't think any physicist would believe that the ultimate test of
truth in physical science is economic exploitation or usefulness.

<P><EM>Skeptic</EM>: Do you agree that science tries to predict things?

<P>Sternberg: Sure, one of the goals of science is prediction.

<P><EM>Skeptic</EM>: Then is your quotation a criticism of psychometrics as a
science or of what we do with its results?

<P>Sternberg: My criticism has nothing to do with scientific truth. It
has a lot to do with what I see as a maladaptive oddity in our
society. We often seem to value the ability to do something more than
what people actually do, and there are lots of examples of that. We
are one of the few societies that place so much emphasis on
intelligence tests. In most societies there is more emphasis on what
people accomplish. I do think there is something to be said for
emphasizing what people actually do, rather than what they might or
might not do. We have gotten into the somewhat ridiculous situation of
even having constructs like "overachiever," which is talked about in
education. Most societies wouldn't have that construct. What does it
mean? An overachiever is somebody whose IQ is lower than their
achievement scores. The idea is that they are achieving too much and
that there is something wrong with them, and that they ought to be
pushed back to their own size.

<P><EM>Skeptic</EM>: It seems logically impossible. 

<P>Sternberg: It is! So where do we get that idea? We got that idea from
valuing the predictive test more than the achievement. You get a lot
of people who work in admissions who will count SAT scores or IQ tests
or ACT tests more than they count actual individual accomplishment. I
think that that is a backward way of looking at things.

<P><EM>Skeptic</EM>: The other side of the argument came out when I interviewed
Douglas Detterman, the editor of <EM>Intelligence</EM>. He reviewed for me the
work at Brooks Air Force Base where g proves to be far and away the
best predictor of pilot training and a whole host of other things. So
getting back to the question of economic reality, the Dallas Cowboys
want to know who's going to make the team before they go through
training (if possible). When I was in the Air Force we had big
problems with washouts from pilot training. It costs a huge amount of
money to put someone through that training. So isn't it just economic
good sense to use the best tests and measures for prediction?

<P>Sternberg: I am not disagreeing that IQ is predictive of a lot of
things. I'm not one of the extreme left-wingers who say that IQ tells
you absolutely nothing. I don't agree with that. So to the extent that
it predicts some level of success in pilot training, I don't have any
argument with that. But I do argue with the idea that IQ is the end of
the line. We have been working for about 10 years in the field of
practical intelligence, predicting, for example, the success of
managers and sales people, which are pretty practical occupations. We
actually did a study at Brooks AFB and found that our measures of
practical intelligence-that is, measures of how well you can go into
an environment and figure out what you need to succeed in that
environment and then actually do it-predict job success in managerial
jobs and in sales jobs at least as well and arguably better than IQ
tests.  Moreover they do not correlate with IQ tests, which means that
(a) IQ is not the only predictor, and (b) the kinds of predictors we
have are relatively independent of IQ. That's not to say that one is
important and the other is not. Rather, it says that both are
important and that there's more to predicting success than just using
IQs. If you want to predict success in jobs, I'm not saying that IQ is
worthless, but I am saying that it's not the only thing you can use.

<P><EM>Skeptic</EM>: Don't we find the situation in sports all the time where we
say, "Hey, this guy came in with great abilities-he runs fast, and so
on-but he just isn't a player, he just doesn't come through. And there
are in baseball, for example, these Billy Martin-type players, who you
think will never make the team, but they play their heart out on every
play. When it's the World Series I know who I want in my lineup. Is
that the sort of argument that you are making?

<P>Sternberg: I think you are talking about something slightly different.
Practical intelligence is different from academic intelligence, and
motivation is something different again. And motivation is also very
important.

<P><EM>Skeptic</EM>: But what about those things in sports like knowing the game,
knowing the tricks of the trade?

<P>Sternberg: That's what I am talking about when I speak of practical
intelligence as opposed to academic intelligence.

<P><EM>Skeptic</EM>: Often the guys who aren't the best players are the best
managers because they've had to learn all this in order to stay in the
league.

<P>Sternberg: And some of them are good players too. You don't need
research to tell you that. We all know people who had very high scores
on SATs, GREs, and IQ tests, who don't seem to be able to translate it
into any kind of success in their lives. It's not to say that everyone
with a high IQ is going to fail. Obviously, that's not true. The other
thing is that a lot of what is said about prediction is, in my view,
somewhat shaded and one can even argue falsified, by the fact that we
have already been using IQ in our society in its various disguises to
create the truth of what is being predicted.  Imagine that we had
decided that in order for someone to succeed in college they had to be
over six feet tall and so you only accepted people who were over six
feet tall. Well, within a generation or two, you would find that most
of the people who were in the high paying jobs were over six feet
tall.  And you would note a correlation between success and being over
six feet tall. But why did you get that correlation? Because you
created a system to make that come true. We have created the kind of
system that Herrnstein and Murray talk about by using SATs for college
and GREs for graduate school, LSATs for law school, and GMATs for
business school. In other words, almost any access route to the
high-paying occupations requires you to do well on these tests. That
will artificially and spuriously create the correlation between high
scores and entering into top jobs. So what Herrnstein and Murray are
talking about when they describe the cognitive stratification of
modern America, is, in fact, an invention of our society.

<P><EM>Skeptic</EM>: But haven't path analysis studies shown that even IQ measured
at an early age is a better predictor than a host of other things
measured later on?

<P>Sternberg: Early childhood IQs do not predict anything accurately. By
around the age of eight, when IQ becomes stable, you are predicting
about 50% of the variation in adult IQ.

<P><EM>Skeptic</EM>: I'm referring to studies that show that childhood IQ predicts
adult earnings. In other words, IQ, rather than being reared in an
affluent home, led to higher adult earnings.

<P>Sternberg: Certainly IQ will be somewhat predictive of
earnings. That's not inconsistent with what I just said. If you have a
high IQ, even if you come from a not very affluent home, you are going
to be rewarded by our society for it. If you come from a poor home and
you do well on the SATs, Yale and Harvard and Princeton will all be
begging to have you so that they can claim diversity. That's the
ticket to success.

<P><EM>Skeptic</EM>: Yes. And wouldn't a lot of people say that that's all for the
better?  That it is extending opportunity in our society beyond what
it was 100 years ago, when everybody at Harvard came from a rich home?

<P>Sternberg: If you ask me, "Is it better to use family affluence or
IQ," I'd say that its better to use IQ. But if you were to ask me, "Is
it better to use IQ or demonstrated accomplishments?" I would say it
is better to use demonstrated accomplishments. My concern is not that
there will be people with high IQs who don't do so well. That's not
the problem. The bigger problem, in my view, is the people who don't
test particularly well, who are going to be screwed. I've seen a lot
of them, including me in my very early years of school.

<P><EM>Skeptic</EM>: Really?

<P>Sternberg: When I was very young, I did poorly on IQ tests because I
was test anxious. The result was that teachers had low expectations
for me and I wanted to please my teachers. So I met their low
expectations. They were happy and I was happy that they were
happy. I've been there and I've seen it happen to lots of people I
know. I got over my test anxiety and then did extremely well on
tests. All of a sudden the expectations were high. To a large extent
it becomes a self-fulfilling prophecy, either way. So when you tell me
that IQ predicts later success, sure it does. You get low scores on
your tests, everything starts to change in your life and you're on a
downhill slide. It's not a controlled experiment, because the very
score itself is having an effect on where you're going to be allowed
to go.

<P><EM>Skeptic</EM>: Do you think it's just as simple as you said, or were you
just citing one specific example?

<P>Sternberg: There are many, many examples of that. Anyone who has ever
worked in college or graduate school admissions, which I have, will
see cases of people who don't test well and therefore aren't
accepted. You can understand the constraints on them. If they let the
average scores go too low, they're going to start losing prestige and
their best students will go somewhere else. So there's pressure to
keep the scores up and there are lots and lots of people who don't
score well on those tests who can't get in anywhere. You don't even
have to do a scientific study to know that. Suppose you're very
creative but you don't test well. You're out of the game. (And no one
is arguing that those tests measure creativity.) So, some people who
are very creative or very good at practical intelligence are not
allowed access and don't make it through that kind of a system. Later
when they are not in such good occupations or making as high a salary,
someone will point out that there is a correlation between IQ and
salary and they will be right-we created it.

<P><EM>Skeptic</EM>: Let me turn briefly to Howard Gardner's "Multiple
Intelligences." In The Triarchic Mind, you say that they should
actually be referred to as talents, rather than intelligences. How is
your criticism of Gardner's model different from the g-theorists'
criticism of Gardner-namely that he is arguing for independence of
things we really wouldn't call intelligences?

<P>Sternberg: There is no absolute, agreed-on definition of
"intelligence." One of the battles in the field, arguably the battle,
even more than the heredity-environment issue, is what you include
under the definition of intelligence. There's no final answer to that
because God doesn't tell us what he means. To a large extent,
intelligence is our own creation. It is a creation to describe the
fact that in terms of adaptive skills, some people have more than
others. I think that you can argue that practical abilities are
adaptive. We showed that they are adaptive for everybody. Everybody
needs the ability to be able to work with other people, to be able to
figure out the environment that they are in. It doesn't matter who you
are. I'm supposedly in the ivory tower, but if you don't have
practical ability, you don't stay here very long. You also need
creative intelligence in the vast majority of jobs and in your life,
because you can't always use solutions that you or someone else came
up with before. Life just isn't that way, especially in very quickly
changing times such as those in which we live. To me, something is a
part of intelligence if it's necessary for adaptation.  What I argue
is that something like musical talent-or musical intelligence-is not
in the same class as practical intelligence. A talent to me is
something that is important in the lives of some people. If you want
to go into music, musical talent or musical intelligence is
important. But for my career even if I was totally tone deaf and never
played any music at all, it wouldn't make any difference to my life or
the life of anyone else.

<P><EM>Skeptic</EM>: This is very similar to what Charles Murray told me when I
interviewed him and asked him about Gardner's work. He said, "g is the
only one that if you do badly enough on it, you end up in a home for
the retarded."

<P>Sternberg: I don't think it is true that g is the only one that if you
do badly, you are screwed in life.

<P><EM>Skeptic</EM>: What other ones are there?

<P>Sternberg: I just told you. You get people who have very high g who
may not end up in a home for the retarded, but their lives don't
differ a whole lot.  They keep screwing up everything they do. And
I've seen them in my own field.  People who are very bitter because
they can't get along with anyone. All of a sudden they find that no
one is inviting them to give talks, they don't stay very long in a
job, no one wants their articles, they don't know how to communicate,
they don't know how to argue for a position effectively, and all the g
in the world doesn't save them.

<P><EM>Skeptic</EM>: Some would say that what you're focusing on are really
personality measures.

<P>Sternberg: Personality is very important for life too, but it's
different from our tests of tacit knowledge. The tests of tacit
knowledge that we use to measure practical intelligence measure what
you know. They do not measure your personality. Introversion and
extroversion are personality measures. The difference is that you can
be very successful in life as an introvert or an extrovert. You can be
successful in life being somewhat altruistic or not very
altruistic. You can't be successful in life if you lack practical
intelligence.

<P><EM>Skeptic</EM>: We live in the computer and information age and although
there are individual differences in speed of learning, so what if it
takes John 100 trials to learn the alphabet but Mary only needs
15. When we were in school, the kid who took longer or who couldn't
throw a baseball as far was ridiculed and embarrassed. But computer
assisted, self-paced learning systems let you go at your own
rate. There's lots of time in childhood, so what's the problem?

<P>Sternberg: You're arguing with the wrong guy. I agree with you. I've
made the same point in some of my writings. Our society is a little
bit unusual in putting so much emphasis on speed.

<P><EM>Skeptic</EM>: It seems to me that a lot of the things that you are
complaining about are the result of a social setting in which we teach
people instead of letting them go at their own rate. If they make a
mistake, they can try it again, but no one gets laughed at. So how
much of your own work has gone towards developing computer-assisted
training systems?

<P>Sternberg: I do a lot of work on training systems, but for the most
part they are not computerized. But the characteristics you're talking
about are not limited to computerized systems. You're talking about
values, not the necessity of using the computer as a medium. I think
the computer is a good medium, but there are other ones as well.

<P><EM>Skeptic</EM>: Turning to your own work, one of the criticisms would be,
"What have you added beyond what's in, say, John B. Carroll's
extensive factor analysis in the domain of abilities?" Or are we going
back to the earlier question in which you said that the practical
intelligence is an equal ability with g, and not just a personality
factor or "tricks of the trade" or just accumulated job knowledge? Are
your tests in fact just job knowledge, rather than a continuing
capacity of the individual?

<P>Sternberg: That criticism is simply false. If you look at the
correlation between tacit knowledge for being an academic researcher
and tacit knowledge for being an executive, the correlation was pretty
high-about .5 to .6. But in terms of teaching job knowledge, probably
no one who is a psychologist went to business school or vice
versa. Tacit knowledge is something you pick up from the
environment. I don't care what you call it. If you want to call it job
knowledge or the ability to use job knowledge or the ability to use
common sense knowledge that you pick up, the name isn't
important. What I'm saying is, whatever you want to call it, it's at
least as important as the academic sort of intelligence and it's not
the same thing as that. I don't need to argue about the name attached
to it.

<P><EM>Skeptic</EM>: Let me turn this around. Suppose that I do great on the SAT
and the GREs and the IQ tests, but I do terribly on Sternberg's
practical knowledge tests. Does that mean that I'm not going to be
allowed to go to graduate school, and instead just sit home and watch
quiz shows? What's your remedy or treatment for that?

<P>Sternberg: Well, I'll tell you what we did. In the program that we
have run for the past two summers here, based on my own model,
students were given my abilities test (which had analytical, creative,
and practical sections), and we admitted kids in the experimental
groups in one of four ways-either very high analytic, very high
creative, very high practical, or balanced. In other words, the model
is that very few people are going to be good in everything.  I wasn't
interested in taking an average. Rather, what I was interested in is
the fact that people have different patterns of strength. What you
want to do is to help them capitalize on whatever their pattern of
strength is. So, if you're very good in analytic, not so high in
practical, that's fine. That's an important kind of skill
too. Analytical skills should not have absolute preference over
creative or practical skills. I'm not saying that these other skills
should have absolute preference over analytical skills.

<P><EM>Skeptic</EM>: Another criticism of your work-I think this was stated by
Messick of the Educational Testing Service-is that you are actually
invoking more explanatory entities than you are measuring, thereby
violating Occam's Razor.  In other words, you have come up with fewer
test measures than entities you have invoked to explain the
measurements you have.

<P>Sternberg: I've talked about analytical, creative, and practical
intelligence and I have measures of all three. If you look at the
Triarchic Theory and you look at all the constructs, for example,
metacomponents (higher order processes) like defining problems, or
setting up strategies to solve problems and you ask if I have a
measure that isolates every single one of those, I don't. Nor do I
particularly want to do what J.P. Guilford did in his career, which
was to spend his whole career filling in the blanks. That's the sign
of an uncreative career, at least in my view. If we talk about the
basic structure of the theory and the three parts of it, I have
measures for all of these, we've used them, and they work. The fact
that Messick works at the Educational Testing Service might give him a
certain vested interest in what ETS does.

<P><EM>Skeptic</EM>: One of the criticisms of <EM>The Bell Curve</EM>, especially the now
infamous Chapter 13 on race differences that the popular press makes a
lot of, is that Herrnstein and Murray have cited the so-called
"Tainted Sources," particularly people who have been funded by the
Pioneer Fund. But some of the individuals funded by the Pioneer Fund
have articles in your own <EM>Encyclopedia of Intelligence</EM>. Do you want to
comment on their work?

<P>Sternberg: I have been offered funds by an organization and I didn't
take the funding because I didn't like the organization. That was my
personal choice.  If they funded my work, the fact that they funded it
doesn't mean that the work is therefore invalid. Work stands or falls
on its own, regardless of who funded it. For example, Messick is at
ETS, so I tend to be somewhat skeptical of people at ETS. But that
doesn't mean that because they're at ETS, what they say is wrong. It
just makes me think twice about what they say.

<P><EM>Skeptic</EM>: The same thing could be turned around said about Sternberg or
Gardner. They have their vested interests.

<P>Sternberg: Absolutely. I agree with that. If you are coming from the
other point of view, you ought to say that I have a vested
interest. That's why I say arguments stand or fall on their own.

<P><EM>Skeptic</EM>: In the <EM>Encyclopedia of Intelligence</EM> you do have articles and
I think even biographies of Arthur Jensen and Hans Eysenck and
others. So you must have some respect for the work they have done, at
least in specific areas.

<P>Sternberg: Even though I may not agree with a lot of what Jensen has
said, the importance of a person's contribution is not determined by
how much I agree with what they say. I think that he's made a
contribution. His work on race I utterly don't like, but I don't think
that that's where his scientific contribution lies. I think his
contribution is the work he's done on reaction time and intelligence.

<P><EM>Skeptic</EM>: If I can summarize, it seems that your main interest is in
the nature of intelligence rather than in the differences between
individuals and groups. Is that right?

<P>Sternberg: I'm interested in both. I just think that what has happened
is that a small part of the question has been treated as if it is the
entire story and it's not.

<P><A HREF = "03.3.contents.html">Return to table of contents.</A>
</BODY>
</HTML>
